# ğŸ’¬ Toxic Comment Classification with Machine Learning  

This repository contains my Project, focusing on **toxic speech detection** using machine learning models. The project evaluates the effectiveness of **Naive Bayes (Generative)** and **Support Vector Machines (Discriminative)** in classifying toxic vs non-toxic comments.  

---

## ğŸ“Œ Overview  
Online platforms face challenges with toxic comments that harm user experience and disrupt communities. This project applies ML techniques to classify comments as toxic or non-toxic, providing insights into the role of AI in content moderation.  

---

## ğŸ¯ Objectives  
- Preprocess and clean text data (tokenization, stopword removal, vectorization).  
- Implement **Naive Bayes** and **SVM** for classification.  
- Compare models based on accuracy, precision, recall, and F1-score.  

---

## ğŸ“‚ Repository Structure  
- **Code/** â†’ Implementation scripts  
- **Data/** â†’ Training, validation, and test datasets  
- **Results/** â†’ Metrics and visualisations  
- **Docs/** â†’ Report and presentation  

---

## âš™ï¸ Installation  
Clone and install requirements:  
```bash
git clone https://github.com/yourusername/Toxic-Comment-Classification-ML.git
cd Toxic-Comment-Classification-ML
pip install -r requirements.txt
